"""
ShadowNet Nexus - Complete System Test
Tests all capabilities end-to-end with real-world scenarios
"""

import os
import time
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()

print("\n" + "="*80)
print("üõ°Ô∏è  SHADOWNET NEXUS - COMPLETE SYSTEM TEST")
print("="*80)
print("Testing all capabilities with real-world ransomware scenarios")
print("="*80)

api_key = os.getenv('GEMINI_API_KEY')
if not api_key:
    print("‚ùå ERROR: GEMINI_API_KEY not found in .env file")
    exit(1)

print(f"\n‚úÖ API Key loaded: {api_key[:20]}...{api_key[-10:]}")

# Import all components
from core.gemini_command_analyzer import GeminiCommandAnalyzer
from core.proactive_evidence_collector import ProactiveEvidenceCollector
from core.siem_integration import SIEMIntegration, SIEMPlatform
from core.alert_manager import AlertManager, AlertChannel, AlertSeverity
from core.gemini_report_generator import GeminiReportGenerator
from core.gemini_report_generator import GeminiReportGenerator
from core.incident_report_generator import IncidentReportGenerator
from core.gemini_behavior_analyzer import GeminiBehaviorAnalyzer
import random

print("\n" + "="*80)
print("üì¶ INITIALIZING SHADOWNET COMPONENTS")
print("="*80)

# Initialize components
analyzer = GeminiCommandAnalyzer(api_key)
collector = ProactiveEvidenceCollector(evidence_vault_path="./evidence", enabled=True)
siem = SIEMIntegration(config={'syslog_server': '127.0.0.1', 'syslog_port': 514})
alert_mgr = AlertManager(config={})
report_gen = GeminiReportGenerator(api_key)
report_gen = GeminiReportGenerator(api_key)
incident_reporter = IncidentReportGenerator(evidence_path="./evidence")
behavior_analyzer = GeminiBehaviorAnalyzer(api_key)

print(f"‚úÖ AI Command Analyzer: {analyzer.model_name}")
print(f"‚úÖ Evidence Collector: {collector.os_type.upper()} (Enabled: {collector.enabled})")
print(f"‚úÖ SIEM Integration: {len(list(SIEMPlatform))} platforms supported")
print(f"‚úÖ Alert Manager: {len(list(AlertChannel))} channels supported")
print(f"‚úÖ Report Generator: {report_gen.model_name}")
print(f"‚úÖ Behavior Analyzer: {behavior_analyzer.model_name}")
print(f"‚úÖ Incident Reporter: Ready")

# Real-world attack scenarios
attack_scenarios = [
    {
        "name": "LockBit 3.0 - Event Log Clearing",
        "command": "wevtutil cl Security",
        "process": {
            "name": "cmd.exe",
            "pid": 4521,
            "parent_name": "powershell.exe",
            "parent_pid": 3210,
            "user": "SYSTEM",
            "timestamp": "2024-01-29T03:42:00",
            "elevated": True,
            "cwd": "C:\\Windows\\System32"
        },
        "expected_threat": True
    },
    {
        "name": "LockBit 3.0 - VSS Deletion",
        "command": "vssadmin delete shadows /all /quiet",
        "process": {
            "name": "cmd.exe",
            "pid": 7721,
            "parent_name": "powershell.exe",
            "parent_pid": 7700,
            "user": "SYSTEM",
            "timestamp": datetime.now().isoformat(),
            "elevated": True,
            "cwd": "C:\\Windows\\System32"
        },
        "expected_threat": True
    },
    {
        "name": "BlackCat - Obfuscated PowerShell",
        "command": "powershell -enc d2V2dHV0aWwgY2wgU2VjdXJpdHk=",
        "process": {
            "name": "excel.exe",
            "pid": 5521,
            "parent_name": "outlook.exe",
            "parent_pid": 2100,
            "user": "user123",
            "timestamp": datetime.now().isoformat(),
            "elevated": False,
            "cwd": "C:\\Users\\user123\\Documents"
        },
        "expected_threat": True
    },
    {
        "name": "Legitimate Admin Activity",
        "command": "wevtutil qe Application /c:10 /rd:true /f:text",
        "process": {
            "name": "powershell.exe",
            "pid": 8821,
            "parent_name": "explorer.exe",
            "parent_pid": 1200,
            "user": "ADMIN",
            "timestamp": "2024-01-29T10:15:00",
            "elevated": True,
            "cwd": "C:\\Users\\Admin"
        },
        "expected_threat": False
    }
]

print("\n" + "="*80)
print(f"üß™ TESTING {len(attack_scenarios)} REAL-WORLD SCENARIOS")
print("="*80)

results = []
threats_detected = 0
false_positives = 0
false_negatives = 0

for i, scenario in enumerate(attack_scenarios, 1):
    print(f"\n[TEST {i}/{len(attack_scenarios)}] {scenario['name']}")
    print(f"Command: {scenario['command']}")
    print(f"Context: {scenario['process']['user']} @ {scenario['process']['timestamp'][:19]}")
    
    try:
        # 1. AI Analysis
        print("\nüîç Step 1: AI Threat Analysis...")
        start_time = time.time()
        analysis = analyzer.analyze_command(scenario['command'], scenario['process'])
        detection_time = time.time() - start_time
        
        is_threat = analysis.get('is_anti_forensics', False)
        confidence = analysis.get('confidence', 0)
        severity = analysis.get('severity', 'UNKNOWN')
        
        print(f"   ‚îú‚îÄ Threat Detected: {is_threat}")
        print(f"   ‚îú‚îÄ Confidence: {confidence:.2%}")
        print(f"   ‚îú‚îÄ Severity: {severity}")
        print(f"   ‚îî‚îÄ Detection Time: {detection_time:.3f}s")
        
        # 2. Evidence Preservation (if threat)
        if is_threat:
            print("\nüíæ Step 2: Proactive Evidence Preservation...")
            evidence_result = collector.on_threat_detected({
                'command': scenario['command'],
                'category': analysis.get('category', 'unknown'),
                'severity': severity,
                'process_info': scenario['process']
            })
            
            if evidence_result.get('snapshot_taken'):
                snapshot_id = evidence_result.get('snapshot_id')
                print(f"   ‚úÖ Evidence preserved: {snapshot_id}")
                
                # Generate incident report
                print("\nüìÑ Step 2b: Generating Incident Report...")
                incident_data = {
                    'incident_id': f"INC-{datetime.now().strftime('%Y%m%d-%H%M%S')}",
                    'threat_type': analysis.get('category', 'unknown'),
                    'command': scenario['command'],
                    'process_info': scenario['process'],
                    'snapshot_id': snapshot_id,
                    'detection_time': datetime.now().isoformat(),
                    'ai_analysis': analysis,
                    'severity': severity,
                    'evidence_types': [
                        'Event Logs (Application, System, Security)',
                        'Process State (All running processes)',
                        'Network Connections (Active TCP/UDP)',
                        'Volume Shadow Copy State',
                        'File System Metadata'
                    ]
                }
                report_path = incident_reporter.generate_incident_report(incident_data)
                print(f"   ‚úÖ Incident report generated: {report_path}")
            else:
                print(f"   ‚ö†Ô∏è  {evidence_result.get('reason', 'Evidence preservation triggered')}")
        
        # 3. SIEM Integration (if threat)
        if is_threat:
            print("\nüì° Step 3: SIEM Event Transmission...")
            siem_event = {
                'type': 'anti_forensics_detected',
                'severity': severity,
                'command': scenario['command'],
                'confidence': confidence,
                'timestamp': datetime.now().isoformat()
            }
            siem_result = siem.send_event(siem_event, [SIEMPlatform.SYSLOG])
            print(f"   ‚úÖ SIEM event sent: {siem_result.get('syslog', False)}")
        
        # 4. Alerting (if critical threat)
        if is_threat and severity == 'CRITICAL':
            print("\nüö® Step 4: Critical Alert...")
            alert_result = alert_mgr.send_alert(
                title=f"{scenario['name']} Detected",
                message=f"Command: {scenario['command']}",
                severity=AlertSeverity.CRITICAL,
                channels=[AlertChannel.CONSOLE],
                metadata={
                    'confidence': f"{confidence:.0%}",
                    'user': scenario['process']['user'],
                    'time': scenario['process']['timestamp'][:19]
                }
            )
            print(f"   ‚úÖ Alert sent: {alert_result.get('console', False)}")
        
        # Validate results
        expected = scenario['expected_threat']
        if is_threat == expected:
            print(f"\n‚úÖ PASS - Correctly {'detected' if is_threat else 'ignored'}")
            if is_threat:
                threats_detected += 1
            results.append({
                'scenario': scenario['name'],
                'status': 'PASS',
                'detected': is_threat,
                'confidence': confidence
            })
        else:
            if is_threat and not expected:
                print(f"\n‚ùå FAIL - False Positive")
                false_positives += 1
            else:
                print(f"\n‚ùå FAIL - Missed Threat")
                false_negatives += 1
            
            results.append({
                'scenario': scenario['name'],
                'status': 'FAIL',
                'detected': is_threat,
                'expected': expected
            })
        
    except Exception as e:
        print(f"\n‚ùå ERROR: {str(e)}")
        results.append({
            'scenario': scenario['name'],
            'status': 'ERROR',
            'error': str(e)
        })
    
    print("-" * 80)
    print("-" * 80)
    time.sleep(2)  # Rate limiting

# --- NEW SECTION: BEHAVIOR ANALYSIS TEST ---
print("\n" + "="*80)
print("üß† TESTING KEYSTROKE DYNAMICS (BEHAVIOR ANALYSIS)")
print("="*80)

# Generate simulation data
# 1. Human (Variable 80-250ms with pauses)
human_timings = []
for _ in range(50):
    delay = random.randint(80, 250)
    if random.random() < 0.1: delay += random.randint(300, 800)
    human_timings.append(delay)

# 2. Bot (Constant 10ms)
bot_timings = [10 + random.randint(0, 2) for _ in range(50)]

behavior_scenarios = [
    {
        "name": "Human Typing Simulation",
        "data": human_timings,
        "expected_human": True
    },
    {
        "name": "Bot/Script Injection (Keylogger Behavior)",
        "data": bot_timings,
        "expected_human": False
    }
]

for i, scenario in enumerate(behavior_scenarios, 1):
    print(f"\n[BEHAVIOR TEST {i}/{len(behavior_scenarios)}] {scenario['name']}")
    print(f"Data Sample: {scenario['data'][:10]}...")
    
    try:
        print("üîç AI Analyzing Keystroke Patterns...")
        start_time = time.time()
        analysis = behavior_analyzer.analyze_keystroke_pattern(scenario['data'])
        detection_time = time.time() - start_time
        
        is_human = analysis.get('is_human', False)
        confidence = analysis.get('confidence', 0)
        
        print(f"   ‚îú‚îÄ Prediction: {'Human' if is_human else 'Bot/Script'}")
        print(f"   ‚îú‚îÄ Confidence: {confidence:.2%}")
        print(f"   ‚îî‚îÄ Time: {detection_time:.3f}s")
        
        # Validation
        passed = (is_human == scenario['expected_human'])
        if passed:
            print(f"\n‚úÖ PASS - Correctly identified as {'Human' if is_human else 'Bot'}")
            results.append({
                'scenario': scenario['name'],
                'status': 'PASS',
                'detected': not is_human, 
                'confidence': confidence
            })
            
            # If a BOT is detected (Threat), generate an incident report
            if not is_human:
                print("\nüö® THREAT CONFIRMED: Bot/Script Activity Detected")
                print("üìÑ Generating Incident Report for Behavioral Threat...")
                incident_data = {
                    'incident_id': f"INC-BEHAVIOR-{datetime.now().strftime('%Y%m%d-%H%M%S')}",
                    'threat_type': 'behavioral_anomaly',
                    'title': 'Automated Keystroke Injection Detected',
                    'command': 'N/A (Behavioral Analysis)',
                    'process_info': {'name': 'unknown_script', 'pid': 'N/A', 'user': 'unknown'},
                    'snapshot_id': 'N/A',
                    'detection_time': datetime.now().isoformat(),
                    'ai_analysis': {
                        'is_human': False,
                        'confidence': confidence,
                        'explanation': 'Keystroke dynamics consistent with automated script execution.'
                    },
                    'severity': 'HIGH',
                    'evidence_types': ['Keystroke Timing Analysis']
                }
                report_path = incident_reporter.generate_incident_report(incident_data)
                print(f"   ‚úÖ Incident report generated: {report_path}")

        else:
            print(f"\n‚ùå FAIL - Identification Mismatch")
            results.append({
                'scenario': scenario['name'],
                'status': 'FAIL',
                'detected': not is_human,
                'confidence': confidence
            })
            
    except Exception as e:
        print(f"\n‚ùå ERROR: {e}")
        results.append({'scenario': scenario['name'], 'status': 'ERROR', 'error': str(e)})
    
    time.sleep(2)

# Generate Incident Report
print("\n" + "="*80)
print("üìÑ GENERATING INCIDENT REPORT")
print("="*80)

if threats_detected > 0:
    incident_data = {
        'incident_id': f'INC-{datetime.now().strftime("%Y%m%d-%H%M%S")}',
        'detection_time': datetime.now().isoformat(),
        'threats_detected': threats_detected,
        'scenarios_tested': len(attack_scenarios),
        'false_positives': false_positives,
        'false_negatives': false_negatives,
        'severity': 'CRITICAL',
        'commands_detected': [s['command'] for s in attack_scenarios if s['expected_threat']]
    }
    
    try:
        print("Generating executive summary...")
        summary = report_gen.generate_executive_summary(incident_data)
        
        if summary and len(summary) > 100:
            print(f"‚úÖ Report generated: {len(summary)} characters")
            print(f"\nPreview:\n{summary[:300]}...")
        else:
            print("‚ö†Ô∏è  Report generation completed with limited output")
    except Exception as e:
        print(f"‚ö†Ô∏è  Report generation: {str(e)[:100]}")

# Final Summary
print("\n" + "="*80)
print("üìä COMPLETE SYSTEM TEST SUMMARY")
print("="*80)

total_threats = sum(1 for s in attack_scenarios if s['expected_threat'])
total_benign = len(attack_scenarios) - total_threats

print(f"\nüìà DETECTION STATISTICS:")
print(f"   Total Scenarios: {len(attack_scenarios)}")
print(f"   ‚îú‚îÄ Actual Threats: {total_threats}")
print(f"   ‚îî‚îÄ Benign Activities: {total_benign}")
print(f"\n   ‚úÖ Threats Detected: {threats_detected}/{total_threats}")
print(f"   ‚ùå Threats Missed: {false_negatives}/{total_threats}")
print(f"   ‚ö†Ô∏è  False Positives: {false_positives}/{total_benign}")

accuracy = (sum(1 for r in results if r['status'] == 'PASS') / len(results)) * 100
print(f"\nüéØ OVERALL ACCURACY: {accuracy:.1f}%")

print(f"\nüìã DETAILED RESULTS:")
for result in results:
    status_icon = {'PASS': '‚úÖ', 'FAIL': '‚ùå', 'ERROR': '‚ùå'}.get(result['status'], '‚ùì')
    print(f"   {status_icon} {result['scenario']}: {result['status']}")

# Component Statistics
print(f"\nüìä COMPONENT STATISTICS:")
print(f"   SIEM Events Sent: {siem.total_events_sent}")
print(f"   Alerts Sent: {alert_mgr.total_alerts_sent}")
print(f"   Evidence Snapshots: {collector.snapshots_taken}")

# Final Verdict
print("\n" + "="*80)
print("üèÜ FINAL VERDICT")
print("="*80)

if accuracy >= 90:
    print("‚úÖ EXCELLENT - System is production-ready!")
    print("   All core capabilities validated successfully")
elif accuracy >= 75:
    print("‚úÖ GOOD - System is functional with minor tuning needed")
    print("   Core capabilities working correctly")
elif accuracy >= 60:
    print("‚ö†Ô∏è  FAIR - System needs improvement")
    print("   Review failed tests and adjust configuration")
else:
    print("‚ùå POOR - System requires significant work")
    print("   Major issues detected, review implementation")

print("\nüí° CAPABILITIES DEMONSTRATED:")
print("   ‚úÖ Real-time threat detection")
print("   ‚úÖ Context-aware AI analysis")
print("   ‚úÖ Proactive evidence preservation")
print("   ‚úÖ SIEM integration")
print("   ‚úÖ Multi-channel alerting")
print("   ‚úÖ Automated report generation")

print("\n" + "="*80)
print("‚úÖ COMPLETE SYSTEM TEST FINISHED")
print("="*80 + "\n")
